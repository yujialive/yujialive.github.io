---
layout: post
title: 用什么做爬虫
categories: live
tags: 
- crawler
---

## 用什么做爬虫
- Python + requests + lxml + celery
> 我是把爬虫的各个功能部分分成小任务, 然后按需放入任务队列中. 这样既能有效的降低爬虫的复杂度, 同时用队列也能提高爬虫的稳健度, 比如失败重做.
还有, 使用celery后你的爬虫就变成分布式的了, 可以简单的布置在多台机器上跑
- Node 	+ jquery
> 前几天 用nodejs写个玩，但不知道怎么部署在只有web服务的 PaaS上－，－
cheerio很好用阿，完全是jQuery的语法。
require('http');require('cheerio');require('iconv').Iconv;require('mongodb');
- Python + requests + pyquery 
- Python + Scrapy (http://scrapy.org/)
- Python + pyquery
- Python + Beautiful Soup + lxml + Scrapy
- Java + jsoup (http://try.jsoup.org/)
- Ruby + norogiri (http://nokogiri.org/)
- PHP + curl\_multi\_*
- PHP + snoopy
- Phantomjs + Casperjs
- Node + cheerio